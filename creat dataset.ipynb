{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#подключим библиотеки\n",
    "from datetime import timedelta\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from deepface import DeepFace\n",
    "\n",
    "from deepface import DeepFace\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Разбиваем выдео на кадры\n",
    "\n",
    "# то есть, если видео длительностью 30 секунд, сохраняется 10 кадров в секунду = всего сохраняется 300 кадров\n",
    "SAVING_FRAMES_PER_SECOND = 10\n",
    "def format_timedelta(td):\n",
    "    \"\"\"Служебная функция для классного форматирования объектов timedelta (например, 00:00:20.05)\n",
    "    исключая микросекунды и сохраняя миллисекунды\"\"\"\n",
    "    result = str(td)\n",
    "    try:\n",
    "        result, ms = result.split(\".\")\n",
    "    except ValueError:\n",
    "        return \"-\" + result + \".00\".replace(\":\", \"-\")\n",
    "    ms = int(ms)\n",
    "    ms = round(ms / 1e4)\n",
    "    return f\"-{result}.{ms:02}\".replace(\":\", \"-\")\n",
    "def get_saving_frames_durations(cap, saving_fps):\n",
    "    \"\"\"Функция, которая возвращает список длительностей сохраняемых кадров\"\"\"\n",
    "    s = []\n",
    "    # получаем длительность клипа, разделив количество кадров на количество кадров в секунду\n",
    "    clip_duration = cap.get(cv2.CAP_PROP_FRAME_COUNT) / cap.get(cv2.CAP_PROP_FPS)\n",
    "    # используем np.arange() для выполнения шагов с плавающей запятой\n",
    "    for i in np.arange(0, clip_duration, 1 / saving_fps):\n",
    "        s.append(i)\n",
    "    return s\n",
    "def main(video_file):\n",
    "    filename, _ = os.path.splitext(video_file)\n",
    "    filename += \"-opencv\"\n",
    "    # создаем папку по названию видео файла\n",
    "    if not os.path.isdir(filename):\n",
    "        os.mkdir(filename)\n",
    "    # читать видео файл    \n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    # получить FPS видео\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    # если наше SAVING_FRAMES_PER_SECOND больше FPS видео, то установливаем минимальное\n",
    "    saving_frames_per_second = min(fps, SAVING_FRAMES_PER_SECOND)\n",
    "    # получить список длительностей кадров для сохранения\n",
    "    saving_frames_durations = get_saving_frames_durations(cap, saving_frames_per_second)\n",
    "    # начало цикла\n",
    "    count = 0\n",
    "    save_count = 0\n",
    "    while True:\n",
    "        is_read, frame = cap.read()\n",
    "        if not is_read:\n",
    "            # выйти из цикла, если нет фреймов для чтения\n",
    "            break\n",
    "        # получаем длительность, разделив текущее количество кадров на FPS\n",
    "        frame_duration = count / fps\n",
    "        try:\n",
    "            # получить самую первоначальную длительность для сохранения\n",
    "            closest_duration = saving_frames_durations[0]\n",
    "        except IndexError:\n",
    "            # список пуст, все кадры сохранены\n",
    "            break\n",
    "        if frame_duration >= closest_duration:\n",
    "            # если ближайшая длительность меньше или равна длительности текущего кадра,\n",
    "            # сохраняем фрейм\n",
    "            frame_duration_formatted = format_timedelta(timedelta(seconds=frame_duration))\n",
    "            saveframe_name = os.path.join(filename, f\"frame{frame_duration_formatted}.jpg\")\n",
    "            \n",
    "            cv2.imwrite(saveframe_name, frame)\n",
    "            save_count += 1\n",
    "            #print(f\"{saveframe_name} сохранён\")\n",
    "            # удалить текущую длительность из списка, так как этот кадр уже сохранен\n",
    "            try:\n",
    "                saving_frames_durations.pop(0)\n",
    "            except IndexError:\n",
    "                pass\n",
    "        # увеличить счечик кадров count\n",
    "        count += 1\n",
    "        \n",
    "    print(f\"Итого сохранено кадров {save_count}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Итого сохранено кадров 254\n"
     ]
    }
   ],
   "source": [
    "main('Z:/2021/1new_dataset/1.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создаем словарь файлов в папке\n",
    "def find_path(root_path):\n",
    "    n = 0;\n",
    "    pul = {}\n",
    "    os.chdir(root_path) #проход по всем файлам в каталоге\n",
    "    for root, dirs, files in tqdm(os.walk(\".\", topdown = False)):\n",
    "        for name in files:\n",
    "            paath = root_path + '/' + name\n",
    "            #print (paath)\n",
    "            pul[n] = paath\n",
    "            n +=1\n",
    "    #print(pul)\n",
    "    return pul\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функциисоздания триплетов\n",
    "faceCascade= cv2.CascadeClassifier(\"Z:/2021/1new_dataset/haarcascade_frontalface_default.xml\")\n",
    "def mix_frame(path1,path2,path3,save_path):\n",
    "    \"\"\"конкатинирует 3 кадра в одну картинку, вырезает область вокруг лица, сораняет результат\"\"\"\n",
    "    \n",
    "    img = cv2.imread(path1)\n",
    "    img1 = cv2.imread(path2)\n",
    "    img2 = cv2.imread(path3)\n",
    "\n",
    "    imgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    imgGray1 = cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)\n",
    "    imgGray2 = cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "    faces = faceCascade.detectMultiScale(imgGray,1.1,4)\n",
    "    if len(faces) > 0:\n",
    "        height, width = img.shape[:2]\n",
    " \n",
    "        for (x,y,w,h) in faces:\n",
    "            dw = round(w/2)\n",
    "            dh = round(h/2)\n",
    "            if x > dw:\n",
    "                xx = x-dw\n",
    "            else:\n",
    "                xx = 0\n",
    "            if y > dh:\n",
    "                yy = y-dh\n",
    "            else:\n",
    "                yy = 0\n",
    "       \n",
    "            xxx = x+w+dw\n",
    "            if xxx > width-1:\n",
    "                xxx = width-1 \n",
    "            yyy = y+h+dh\n",
    "            if yyy > height-1:\n",
    "                yyy = height-1\n",
    "            \n",
    "            cv2.rectangle(img,(xx,yy),(xxx,yyy),(255,0,0),2)\n",
    "    \n",
    "        img[:,:,0] = imgGray\n",
    "        img[:,:,1] = imgGray1\n",
    "        img[:,:,2] = imgGray2\n",
    "    #cv2.rectangle(img,(xx,yy),(xxx,yyy),(255,0,0),2)\n",
    "        Area = img[yy:yyy, xx:xxx]\n",
    "        cv2.imwrite(save_path, Area)\n",
    "        return Area\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def mix_frame0(path1,path2,path3,save_path):\n",
    "    \"\"\"конкатинирует 3 кадра в одну картинку, не ищет лицо\"\"\"\n",
    "    \n",
    "    img = cv2.imread(path1)\n",
    "    img1 = cv2.imread(path2)\n",
    "    img2 = cv2.imread(path3)\n",
    "\n",
    "    imgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    imgGray1 = cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)\n",
    "    imgGray2 = cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "    \n",
    "    img[:,:,0] = imgGray\n",
    "    img[:,:,1] = imgGray1\n",
    "    img[:,:,2] = imgGray2\n",
    "    \n",
    "    cv2.imwrite(save_path, img)\n",
    "    return img\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 111.10it/s]\n"
     ]
    }
   ],
   "source": [
    "#папка с исходными картинками\n",
    "ppp = find_path('Z:/2021/1new_dataset/1-opencv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# прходим по папке, создаем триплеты\n",
    "len_dict = len(ppp) - 2\n",
    "save_path, _ = os.path.split(ppp[0])\n",
    "save_path +='/0/'\n",
    "if  not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)\n",
    "\n",
    "#save_path = 'Z:/2021/1new_dataset/3/'\n",
    "for n in ppp:\n",
    "    #print(len_dict)\n",
    "    if n < len_dict:\n",
    "        path1 = ppp[n]\n",
    "        path2 = ppp[n+1]\n",
    "        path3 = ppp[n+2]\n",
    "        mix_frame0(path1,path2,path3,save_path+str(n)+'.png')\n",
    "        #mix_frame0(path1,path1,path1,save_path+str(n)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Конвертация датасета WIDER FACE в формат tfrecord\n",
    "#в папке назначения функция ожидает найти паку  images и исходными изображениями и файл  label.txt с метками\n",
    "\n",
    "\n",
    "import os\n",
    "import tqdm\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy()\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
    "\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "\n",
    "def make_example(img_name, img_path, target, is_binary):\n",
    "    # Create a dictionary with features that may be relevant.\n",
    "    feature = {'image/img_name': _bytes_feature([img_name]),\n",
    "               'image/object/bbox/xmin': _float_feature(target[:, 0]),\n",
    "               'image/object/bbox/ymin': _float_feature(target[:, 1]),\n",
    "               'image/object/bbox/xmax': _float_feature(target[:, 2]),\n",
    "               'image/object/bbox/ymax': _float_feature(target[:, 3]),\n",
    "               'image/object/landmark0/x': _float_feature(target[:, 4]),\n",
    "               'image/object/landmark0/y': _float_feature(target[:, 5]),\n",
    "               'image/object/landmark1/x': _float_feature(target[:, 6]),\n",
    "               'image/object/landmark1/y': _float_feature(target[:, 7]),\n",
    "               'image/object/landmark2/x': _float_feature(target[:, 8]),\n",
    "               'image/object/landmark2/y': _float_feature(target[:, 9]),\n",
    "               'image/object/landmark3/x': _float_feature(target[:, 10]),\n",
    "               'image/object/landmark3/y': _float_feature(target[:, 11]),\n",
    "               'image/object/landmark4/x': _float_feature(target[:, 12]),\n",
    "               'image/object/landmark4/y': _float_feature(target[:, 13]),\n",
    "               'image/object/landmark/valid': _float_feature(target[:, 14])}\n",
    "    if is_binary:\n",
    "        img_str = open(img_path, 'rb').read()\n",
    "        feature['image/encoded'] = _bytes_feature([img_str])\n",
    "    else:\n",
    "        feature['image/img_path'] = _bytes_feature([img_path])\n",
    "\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "\n",
    "def load_info(txt_path):\n",
    "    \"\"\"load info from txt\"\"\"\n",
    "    img_paths = []\n",
    "    words = []\n",
    "\n",
    "    f = open(txt_path, 'r')\n",
    "    lines = f.readlines()\n",
    "    isFirst = True\n",
    "    labels = []\n",
    "    for line in lines:\n",
    "        line = line.rstrip()\n",
    "        if line.startswith('#'):\n",
    "            if isFirst is True:\n",
    "                isFirst = False\n",
    "            else:\n",
    "                labels_copy = labels.copy()\n",
    "                words.append(labels_copy)\n",
    "                labels.clear()\n",
    "            path = line[2:]\n",
    "            path = txt_path.replace('label.txt', 'images/') + path\n",
    "            img_paths.append(path)\n",
    "        else:\n",
    "            line = line.split(' ')\n",
    "            label = [float(x) for x in line]\n",
    "            labels.append(label)\n",
    "\n",
    "    words.append(labels)\n",
    "    return img_paths, words\n",
    "\n",
    "\n",
    "def get_target(labels):\n",
    "    annotations = np.zeros((0, 15))\n",
    "    if len(labels) == 0:\n",
    "        return annotations\n",
    "    for idx, label in enumerate(labels):\n",
    "        annotation = np.zeros((1, 15))\n",
    "        # bbox\n",
    "        annotation[0, 0] = label[0]  # x1\n",
    "        annotation[0, 1] = label[1]  # y1\n",
    "        annotation[0, 2] = label[0] + label[2]  # x2\n",
    "        annotation[0, 3] = label[1] + label[3]  # y2\n",
    "\n",
    "        # landmarks\n",
    "        annotation[0, 4] = label[4]    # l0_x\n",
    "        annotation[0, 5] = label[5]    # l0_y\n",
    "        annotation[0, 6] = label[7]    # l1_x\n",
    "        annotation[0, 7] = label[8]    # l1_y\n",
    "        annotation[0, 8] = label[10]   # l2_x\n",
    "        annotation[0, 9] = label[11]   # l2_y\n",
    "        annotation[0, 10] = label[13]  # l3_x\n",
    "        annotation[0, 11] = label[14]  # l3_y\n",
    "        annotation[0, 12] = label[16]  # l4_x\n",
    "        annotation[0, 13] = label[17]  # l4_y\n",
    "        if (annotation[0, 4] < 0):\n",
    "            annotation[0, 14] = -1  # w/o landmark\n",
    "        else:\n",
    "            annotation[0, 14] = 1\n",
    "\n",
    "        annotations = np.append(annotations, annotation, axis=0)\n",
    "    target = np.array(annotations)\n",
    "\n",
    "    return target\n",
    "\n",
    "\n",
    "def to_tfrecord():\n",
    "    dataset_path = './data/widerface/train'\n",
    "    output_path = './data/widerface_train_bin.tfrecord'\n",
    "\n",
    "    if not os.path.isdir(dataset_path):\n",
    "        logging.info('Please define valid dataset path.')\n",
    "    else:\n",
    "        logging.info('Loading {}'.format(dataset_path))\n",
    "\n",
    "    logging.info('Reading data list...')\n",
    "    img_paths, words = load_info(os.path.join(dataset_path, 'label.txt'))\n",
    "    samples = list(zip(img_paths, words))\n",
    "    random.shuffle(samples)\n",
    "\n",
    "    if os.path.exists(output_path):\n",
    "        logging.info('{:s} already exists. Exit...'.format(\n",
    "            output_path))\n",
    "        exit()\n",
    "\n",
    "    logging.info('Writing {} sample to tfrecord file...'.format(len(samples)))\n",
    "    with tf.io.TFRecordWriter(output_path) as writer:\n",
    "        for img_path, word in tqdm.tqdm(samples):\n",
    "            target = get_target(word)\n",
    "            img_name = os.path.basename(img_path).replace('.jpg', '')\n",
    "\n",
    "            tf_example = make_example(img_name=str.encode(img_name),\n",
    "                                      img_path=str.encode(img_path),\n",
    "                                      target=target,\n",
    "                                      is_binary=True)\n",
    "\n",
    "            writer.write(tf_example.SerializeToString())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-15e216f3001e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Color all'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Color blue'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Color green'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Color red'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "cv2.imshow('Color all',img)\n",
    "cv2.imshow('Color blue',img[:,:,0])\n",
    "cv2.imshow('Color green',img[:,:,1])\n",
    "cv2.imshow('Color red',img[:,:,2])\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mtcnn import MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.cvtColor(cv2.imread(\"Z:/2021/1new_dataset/6.png\"), cv2.COLOR_BGR2RGB)\n",
    "detector = MTCNN()\n",
    "result = detector.detect_faces(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Result is an array with all the bounding boxes detected. We know that for 'ivan.jpg' there is only one.\n",
    "bounding_box = result[0]['box']\n",
    "keypoints = result[0]['keypoints']\n",
    "\n",
    "cv2.rectangle(image,\n",
    "              (bounding_box[0], bounding_box[1]),\n",
    "              (bounding_box[0]+bounding_box[2], bounding_box[1] + bounding_box[3]),\n",
    "              (0,155,255),\n",
    "              2)\n",
    "\n",
    "cv2.circle(image,(keypoints['left_eye']), 2, (0,155,255), 2)\n",
    "cv2.circle(image,(keypoints['right_eye']), 2, (0,155,255), 2)\n",
    "cv2.circle(image,(keypoints['nose']), 2, (0,155,255), 2)\n",
    "cv2.circle(image,(keypoints['mouth_left']), 2, (0,155,255), 2)\n",
    "cv2.circle(image,(keypoints['mouth_right']), 2, (0,155,255), 2)\n",
    "\n",
    "cv2.imwrite(\"ivan_drawn.jpg\", cv2.cvtColor(image, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
